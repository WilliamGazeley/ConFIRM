{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple notebook used to split the final dataset into subsets - only used when doing research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import csv, json\n",
    "\n",
    "dataset_path = \"./ocean/ocean_rephrased_validated_descriptive.csv\"\n",
    "\n",
    "text_column = \"question\"\n",
    "label_column = \"expected_fields\"\n",
    "    \n",
    "# dataset from from local path\n",
    "def get_successful(all_data):\n",
    "    successful=[]\n",
    "    for obj in all_data:\n",
    "        if type(obj[label_column]) == list:\n",
    "            obj[label_column] = str(obj[label_column])\n",
    "            \n",
    "        # handling for old dataset with quality column\n",
    "        if \"quality\" in obj:\n",
    "            if obj[\"quality\"] == \"1\" or obj[\"quality\"] == \"2\":\n",
    "                successful.append(obj)\n",
    "                \n",
    "        # new dataset without quality column\n",
    "        else:\n",
    "            successful.append(obj)\n",
    "    return successful\n",
    "            \n",
    "if \".csv\" in dataset_path:\n",
    "    with open(dataset_path, \"r\") as f:\n",
    "        csv_reader = csv.DictReader(f)\n",
    "        successful = get_successful(csv_reader)\n",
    "elif \".json\" in dataset_path:\n",
    "    with open(dataset_path, \"r\") as f:\n",
    "        qa_pairs = json.load(f)\n",
    "        successful = get_successful(qa_pairs)\n",
    "else:\n",
    "    raise ValueError(\"unsupported dataset file format.\")\n",
    "\n",
    "dataset = Dataset.from_list(successful)\n",
    "dataset = dataset.shuffle()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100, 200, 500, 1500, 3000\n",
    "\n",
    "dataset_test_1000n = Dataset.from_dict(dataset[-1000:])\n",
    "dataset = Dataset.from_dict(dataset[:-1000])\n",
    "\n",
    "dataset_train_110n = Dataset.from_dict(dataset[:110])\n",
    "dataset_train_220n = Dataset.from_dict(dataset[:220])\n",
    "dataset_train_550n = Dataset.from_dict(dataset[:550])\n",
    "dataset_train_1650n = Dataset.from_dict(dataset[:1650])\n",
    "dataset_train_3300n = Dataset.from_dict(dataset[:3300])\n",
    "\n",
    "train_sets = [\n",
    "    dataset_train_110n,\n",
    "    dataset_train_220n,\n",
    "    dataset_train_550n,\n",
    "    dataset_train_1650n,\n",
    "    dataset_train_3300n\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating CSV from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 686.47ba/s]\n",
      "Creating CSV from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 643.69ba/s]\n",
      "Creating CSV from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 441.55ba/s]\n",
      "Creating CSV from Arrow format: 100%|██████████| 2/2 [00:00<00:00, 361.81ba/s]\n",
      "Creating CSV from Arrow format: 100%|██████████| 4/4 [00:00<00:00, 360.05ba/s]\n",
      "Creating CSV from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 303.58ba/s]\n",
      "Creating CSV from Arrow format: 100%|██████████| 2/2 [00:00<00:00, 360.74ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "262267"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for train_set in train_sets:\n",
    "    train_set.to_csv(dataset_path.removesuffix(\".csv\") + f\"_{len(train_set)}n_train.csv\")\n",
    "    \n",
    "dataset_test_1000n.to_csv(dataset_path.removesuffix(\".csv\") + f\"_{len(dataset_test_1000n)}n_test.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "confirm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
